{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import time\n",
    "import lightgbm\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(model, splits, X, y):\n",
    "    mae = []\n",
    "    mse = []\n",
    "    r2 = []\n",
    "    rms = []\n",
    "\n",
    "    kf = KFold(5, shuffle=True, random_state=42)\n",
    "    for train_ind, test_ind in kf.split(X):\n",
    "\n",
    "        X_train, Y_train = X.iloc[train_ind], y.iloc[train_ind]\n",
    "        X_test, Y_test = X.iloc[test_ind], y.iloc[test_ind]\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "            # Calculate metrics\n",
    "        mae_r = mean_absolute_error(Y_test, y_pred)\n",
    "        mse_r = mean_squared_error(Y_test, y_pred)\n",
    "        rmse_r = np.sqrt(mse)\n",
    "        r2_r = r2_score(Y_test, y_pred)\n",
    "\n",
    "        # Output metrics\n",
    "        mae.append(mae_r)\n",
    "        mse.append(mse_r)\n",
    "        rms.append(rmse_r)\n",
    "        r2.append(r2_r)\n",
    "\n",
    "    print(\"MAE = \", mae)\n",
    "    print(\"MSE = \", mse)\n",
    "    print(\"rms = \", rms)\n",
    "    print(\"r2 = \", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'chips': [...],\n",
      "  'element_stats': [...],\n",
      "  'element_types': [...],\n",
      "  'elements': [...],\n",
      "  'events': [...],\n",
      "  'game_config': {...},\n",
      "  'game_settings': {...},\n",
      "  'phases': [...],\n",
      "  'teams': [...],\n",
      "  'total_players': 11154687}\n",
      "{'fixtures': [...], 'history': [...], 'history_past': [...]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:48<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id_player      web_name  element  fixture  opponent_team  total_points  \\\n",
      "0              1  Fábio Vieira        1        2             20             0   \n",
      "11             1  Fábio Vieira        1      111             16             0   \n",
      "3              1  Fábio Vieira        1       39             18             0   \n",
      "5              1  Fábio Vieira        1       51             11             0   \n",
      "17             1  Fábio Vieira        1      171             10             0   \n",
      "...          ...           ...      ...      ...            ...           ...   \n",
      "7488         708  Wilson-Brown      708      191              2             0   \n",
      "8077         709         Danns      709      190             19             0   \n",
      "8078         709         Danns      709      196             14             0   \n",
      "1376         710         Jimoh      710      191             11             0   \n",
      "13453        711       Okoduwa      711      200             16             0   \n",
      "\n",
      "       was_home          kickoff_time  team_h_score  team_a_score  round  \\\n",
      "0          True  2024-08-17T14:00:00Z             2             0      1   \n",
      "11         True  2024-11-23T15:00:00Z             3             0     12   \n",
      "3         False  2024-09-15T13:00:00Z             0             1      4   \n",
      "5          True  2024-09-28T14:00:00Z             4             2      6   \n",
      "17         True  2024-12-27T20:15:00Z             1             0     18   \n",
      "...         ...                   ...           ...           ...    ...   \n",
      "7488      False  2025-01-04T15:00:00Z             2             1     20   \n",
      "8077      False  2024-12-29T17:15:00Z             0             5     19   \n",
      "8078       True  2025-01-05T16:30:00Z             2             2     20   \n",
      "1376       True  2025-01-04T15:00:00Z             2             1     20   \n",
      "13453      True  2025-01-06T20:00:00Z             0             3     20   \n",
      "\n",
      "       modified  minutes  goals_scored  assists  clean_sheets  goals_conceded  \\\n",
      "0         False        0             0        0             0               0   \n",
      "11        False        0             0        0             0               0   \n",
      "3         False        0             0        0             0               0   \n",
      "5         False        0             0        0             0               0   \n",
      "17        False        0             0        0             0               0   \n",
      "...         ...      ...           ...      ...           ...             ...   \n",
      "7488      False        0             0        0             0               0   \n",
      "8077      False        0             0        0             0               0   \n",
      "8078      False        0             0        0             0               0   \n",
      "1376      False        0             0        0             0               0   \n",
      "13453     False        0             0        0             0               0   \n",
      "\n",
      "       own_goals  penalties_saved  penalties_missed  yellow_cards  red_cards  \\\n",
      "0              0                0                 0             0          0   \n",
      "11             0                0                 0             0          0   \n",
      "3              0                0                 0             0          0   \n",
      "5              0                0                 0             0          0   \n",
      "17             0                0                 0             0          0   \n",
      "...          ...              ...               ...           ...        ...   \n",
      "7488           0                0                 0             0          0   \n",
      "8077           0                0                 0             0          0   \n",
      "8078           0                0                 0             0          0   \n",
      "1376           0                0                 0             0          0   \n",
      "13453          0                0                 0             0          0   \n",
      "\n",
      "       saves  bonus  bps influence creativity threat ict_index  starts  \\\n",
      "0          0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "11         0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "3          0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "5          0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "17         0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "...      ...    ...  ...       ...        ...    ...       ...     ...   \n",
      "7488       0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "8077       0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "8078       0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "1376       0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "13453      0      0    0       0.0        0.0    0.0       0.0       0   \n",
      "\n",
      "      expected_goals expected_assists expected_goal_involvements  \\\n",
      "0               0.00             0.00                       0.00   \n",
      "11              0.00             0.00                       0.00   \n",
      "3               0.00             0.00                       0.00   \n",
      "5               0.00             0.00                       0.00   \n",
      "17              0.00             0.00                       0.00   \n",
      "...              ...              ...                        ...   \n",
      "7488            0.00             0.00                       0.00   \n",
      "8077            0.00             0.00                       0.00   \n",
      "8078            0.00             0.00                       0.00   \n",
      "1376            0.00             0.00                       0.00   \n",
      "13453           0.00             0.00                       0.00   \n",
      "\n",
      "      expected_goals_conceded  value  transfers_balance  selected  \\\n",
      "0                        0.00     55                  0      2923   \n",
      "11                       0.00     54                -13      1202   \n",
      "3                        0.00     54               -747      1650   \n",
      "5                        0.00     54               -110      1387   \n",
      "17                       0.00     54                 -9      1152   \n",
      "...                       ...    ...                ...       ...   \n",
      "7488                     0.00     40                174       324   \n",
      "8077                     0.00     45                  0         0   \n",
      "8078                     0.00     45                621       849   \n",
      "1376                     0.00     45                  0         0   \n",
      "13453                    0.00     40                  0         0   \n",
      "\n",
      "       transfers_in  transfers_out  cumulative_points  \n",
      "0                 0              0                  0  \n",
      "11                0             13                  0  \n",
      "3                 0            747                  0  \n",
      "5                 0            110                  0  \n",
      "17                0              9                  0  \n",
      "...             ...            ...                ...  \n",
      "7488            190             16                  0  \n",
      "8077              0              0                  0  \n",
      "8078            788            167                  0  \n",
      "1376              0              0                  0  \n",
      "13453             0              0                  0  \n",
      "\n",
      "[13454 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "%run data_download_from_fpl.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_data_2 = past_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert all object columns to float\n",
    "for col in past_data_2.select_dtypes(include=['object']).columns:\n",
    "    past_data_2[col] = pd.to_numeric(past_data_2[col], errors='coerce')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML MODEL PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = past_data_2.drop(columns = ['total_points', 'event'])\n",
    "y = past_data_2[['total_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = lightgbm.LGBMRegressor(alpha=0.1, l1_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1063\n",
      "[LightGBM] [Info] Number of data points in the train set: 10763, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 1.210629\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fitzm\\anaconda3\\envs\\fantasy\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fitzm\\anaconda3\\envs\\fantasy\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1063\n",
      "[LightGBM] [Info] Number of data points in the train set: 10763, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 1.233392\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1062\n",
      "[LightGBM] [Info] Number of data points in the train set: 10763, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 1.188237\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1064\n",
      "[LightGBM] [Info] Number of data points in the train set: 10763, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 1.198458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fitzm\\anaconda3\\envs\\fantasy\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fitzm\\anaconda3\\envs\\fantasy\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fitzm\\anaconda3\\envs\\fantasy\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 10764, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 1.206522\n",
      "[LightGBM] [Warning] Unknown parameter: l1_ratio\n",
      "MAE =  [0.20885688183227638, 0.19962158829197685, 0.22071634075895186, 0.21135924887363572, 0.21035797246637636]\n",
      "MSE =  [0.2512492251480871, 0.20692805865314798, 0.2607190289634553, 0.22046580062514967, 0.21600149185513917]\n",
      "rms =  [array([], dtype=float64), array([0.50124767]), array([0.50124767, 0.45489346]), array([0.50124767, 0.45489346, 0.51060653]), array([0.50124767, 0.45489346, 0.51060653, 0.46953786])]\n",
      "r2 =  [0.9550037776755026, 0.9578598225200124, 0.9589986921964901, 0.9610855184068962, 0.9600713715874369]\n"
     ]
    }
   ],
   "source": [
    "kfold_cross_validation(model, 5, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN ML MODEl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 23:19:43,140] A new study created in memory with name: no-name-9e121fe2-3ff6-4f49-ac38-389ad89474f2\n",
      "C:\\Users\\fitzm\\AppData\\Local\\Temp\\ipykernel_24936\\3440830950.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_learning_rate = trial.suggest_loguniform('learning_rate', 0.1, 1)\n",
      "C:\\Users\\fitzm\\AppData\\Local\\Temp\\ipykernel_24936\\3440830950.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_lambda_l1 = trial.suggest_loguniform('lambda_l1', 0.1, 1)\n",
      "[I 2025-01-13 23:19:45,557] Trial 0 finished with value: 0.9525795831139376 and parameters: {'num_leaves': 29, 'learning_rate': 0.21466723459783427, 'n_estimators': 84, 'lambda_l1': 0.4366729921483321}. Best is trial 0 with value: 0.9525795831139376.\n",
      "[I 2025-01-13 23:19:47,106] Trial 1 finished with value: 0.9463295044814096 and parameters: {'num_leaves': 27, 'learning_rate': 0.46417096715830475, 'n_estimators': 97, 'lambda_l1': 0.14513982187244884}. Best is trial 0 with value: 0.9525795831139376.\n",
      "[I 2025-01-13 23:19:48,701] Trial 2 finished with value: 0.9528152716625812 and parameters: {'num_leaves': 31, 'learning_rate': 0.18511068193990834, 'n_estimators': 80, 'lambda_l1': 0.37453715134231497}. Best is trial 2 with value: 0.9528152716625812.\n",
      "[I 2025-01-13 23:19:50,214] Trial 3 finished with value: 0.936735936482061 and parameters: {'num_leaves': 2, 'learning_rate': 0.6069119949936459, 'n_estimators': 75, 'lambda_l1': 0.35111487984056716}. Best is trial 2 with value: 0.9528152716625812.\n",
      "[I 2025-01-13 23:19:51,767] Trial 4 finished with value: 0.9481080329988246 and parameters: {'num_leaves': 7, 'learning_rate': 0.8331541028960848, 'n_estimators': 58, 'lambda_l1': 0.35587639832630535}. Best is trial 2 with value: 0.9528152716625812.\n",
      "[I 2025-01-13 23:19:53,119] Trial 5 finished with value: 0.935199359569851 and parameters: {'num_leaves': 16, 'learning_rate': 0.9468419375208543, 'n_estimators': 48, 'lambda_l1': 0.7093588243065441}. Best is trial 2 with value: 0.9528152716625812.\n",
      "[I 2025-01-13 23:19:53,209] Trial 6 finished with value: 0.9405896257397659 and parameters: {'num_leaves': 13, 'learning_rate': 0.7759316408943975, 'n_estimators': 41, 'lambda_l1': 0.1559184288573274}. Best is trial 2 with value: 0.9528152716625812.\n",
      "[I 2025-01-13 23:19:53,289] Trial 7 finished with value: 0.949577720130988 and parameters: {'num_leaves': 4, 'learning_rate': 0.20033549963611375, 'n_estimators': 68, 'lambda_l1': 0.4499484059565489}. Best is trial 2 with value: 0.9528152716625812.\n",
      "[I 2025-01-13 23:19:53,537] Trial 8 finished with value: 0.9545113106790044 and parameters: {'num_leaves': 22, 'learning_rate': 0.10659354594597335, 'n_estimators': 79, 'lambda_l1': 0.2235055794984093}. Best is trial 8 with value: 0.9545113106790044.\n",
      "[I 2025-01-13 23:19:53,619] Trial 9 finished with value: 0.9470876332830764 and parameters: {'num_leaves': 3, 'learning_rate': 0.2962454043984623, 'n_estimators': 57, 'lambda_l1': 0.25788753886536675}. Best is trial 8 with value: 0.9545113106790044.\n",
      "[I 2025-01-13 23:19:53,706] Trial 10 finished with value: 0.6840207615335511 and parameters: {'num_leaves': 23, 'learning_rate': 0.10327988523791275, 'n_estimators': 6, 'lambda_l1': 0.10780984024403845}. Best is trial 8 with value: 0.9545113106790044.\n",
      "[I 2025-01-13 23:19:53,928] Trial 11 finished with value: 0.9544333906104892 and parameters: {'num_leaves': 22, 'learning_rate': 0.10037086668340355, 'n_estimators': 100, 'lambda_l1': 0.2247797673551731}. Best is trial 8 with value: 0.9545113106790044.\n",
      "[I 2025-01-13 23:19:54,158] Trial 12 finished with value: 0.9542912781603964 and parameters: {'num_leaves': 22, 'learning_rate': 0.11473177236206261, 'n_estimators': 97, 'lambda_l1': 0.20761730143242355}. Best is trial 8 with value: 0.9545113106790044.\n",
      "[I 2025-01-13 23:19:54,370] Trial 13 finished with value: 0.9552355298321409 and parameters: {'num_leaves': 22, 'learning_rate': 0.1254687716030747, 'n_estimators': 100, 'lambda_l1': 0.215089500544095}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:54,487] Trial 14 finished with value: 0.9541229515654673 and parameters: {'num_leaves': 18, 'learning_rate': 0.14809480746991233, 'n_estimators': 31, 'lambda_l1': 0.1746895161043226}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:54,708] Trial 15 finished with value: 0.954411296899632 and parameters: {'num_leaves': 25, 'learning_rate': 0.14816727229445226, 'n_estimators': 87, 'lambda_l1': 0.10501996909476731}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:54,866] Trial 16 finished with value: 0.9526409052687553 and parameters: {'num_leaves': 18, 'learning_rate': 0.29728920474258197, 'n_estimators': 70, 'lambda_l1': 0.6197483367826593}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:55,015] Trial 17 finished with value: 0.9543972320586245 and parameters: {'num_leaves': 11, 'learning_rate': 0.14083337242408633, 'n_estimators': 90, 'lambda_l1': 0.28440338972810636}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:55,121] Trial 18 finished with value: 0.9522518091442823 and parameters: {'num_leaves': 20, 'learning_rate': 0.379144755585457, 'n_estimators': 19, 'lambda_l1': 0.9004344486093184}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:55,270] Trial 19 finished with value: 0.953815511164328 and parameters: {'num_leaves': 15, 'learning_rate': 0.21987541483355016, 'n_estimators': 64, 'lambda_l1': 0.19760797139061453}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:55,491] Trial 20 finished with value: 0.9546257939510543 and parameters: {'num_leaves': 26, 'learning_rate': 0.1329444063456184, 'n_estimators': 79, 'lambda_l1': 0.12020153380675135}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:55,735] Trial 21 finished with value: 0.9542445266832695 and parameters: {'num_leaves': 25, 'learning_rate': 0.13147147434794587, 'n_estimators': 77, 'lambda_l1': 0.13085023778747404}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:55,958] Trial 22 finished with value: 0.9532862328250697 and parameters: {'num_leaves': 26, 'learning_rate': 0.173274746160733, 'n_estimators': 92, 'lambda_l1': 0.12764343367021455}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:56,185] Trial 23 finished with value: 0.9548268867105101 and parameters: {'num_leaves': 29, 'learning_rate': 0.12512741684401735, 'n_estimators': 85, 'lambda_l1': 0.244096782047608}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:56,505] Trial 24 finished with value: 0.951475122621634 and parameters: {'num_leaves': 31, 'learning_rate': 0.24844081446014574, 'n_estimators': 91, 'lambda_l1': 0.2842108734553015}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:56,751] Trial 25 finished with value: 0.9546372810081145 and parameters: {'num_leaves': 28, 'learning_rate': 0.12655637823996851, 'n_estimators': 85, 'lambda_l1': 0.16575003870578267}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:57,018] Trial 26 finished with value: 0.9523880402381962 and parameters: {'num_leaves': 28, 'learning_rate': 0.16696138896670892, 'n_estimators': 99, 'lambda_l1': 0.18341156087600488}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:57,269] Trial 27 finished with value: 0.9541536470153585 and parameters: {'num_leaves': 29, 'learning_rate': 0.1243798469116811, 'n_estimators': 87, 'lambda_l1': 0.15901934838252044}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:57,461] Trial 28 finished with value: 0.9537992681131323 and parameters: {'num_leaves': 24, 'learning_rate': 0.16260438191129487, 'n_estimators': 71, 'lambda_l1': 0.2344871944255236}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:57,695] Trial 29 finished with value: 0.9524812506009148 and parameters: {'num_leaves': 29, 'learning_rate': 0.23853886826597645, 'n_estimators': 84, 'lambda_l1': 0.29602569009076635}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:57,855] Trial 30 finished with value: 0.9507877532982599 and parameters: {'num_leaves': 20, 'learning_rate': 0.3584023945634769, 'n_estimators': 63, 'lambda_l1': 0.1741371292832329}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:58,091] Trial 31 finished with value: 0.9543448789126548 and parameters: {'num_leaves': 27, 'learning_rate': 0.12337104775500315, 'n_estimators': 82, 'lambda_l1': 0.1185822393556791}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:58,358] Trial 32 finished with value: 0.9542135732851597 and parameters: {'num_leaves': 31, 'learning_rate': 0.12403305651035862, 'n_estimators': 95, 'lambda_l1': 0.14554229591989046}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:58,572] Trial 33 finished with value: 0.9532468394799852 and parameters: {'num_leaves': 27, 'learning_rate': 0.19223850644418058, 'n_estimators': 74, 'lambda_l1': 0.13826243871542526}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:58,806] Trial 34 finished with value: 0.9540661076112683 and parameters: {'num_leaves': 30, 'learning_rate': 0.14848473532185869, 'n_estimators': 81, 'lambda_l1': 0.1910810175146479}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:59,043] Trial 35 finished with value: 0.9458288781808001 and parameters: {'num_leaves': 28, 'learning_rate': 0.47064969664891076, 'n_estimators': 93, 'lambda_l1': 0.25091786693398255}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:59,278] Trial 36 finished with value: 0.9544364523297371 and parameters: {'num_leaves': 25, 'learning_rate': 0.11449371622752302, 'n_estimators': 86, 'lambda_l1': 0.16213761950328254}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:59,431] Trial 37 finished with value: 0.9546770674528339 and parameters: {'num_leaves': 20, 'learning_rate': 0.16047583369729188, 'n_estimators': 48, 'lambda_l1': 0.44430512832124025}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:59,572] Trial 38 finished with value: 0.954132410043994 and parameters: {'num_leaves': 20, 'learning_rate': 0.1820920022291022, 'n_estimators': 43, 'lambda_l1': 0.5352543213311323}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:59,691] Trial 39 finished with value: 0.9539769008250835 and parameters: {'num_leaves': 17, 'learning_rate': 0.15923036861281692, 'n_estimators': 34, 'lambda_l1': 0.40855751774519855}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:59,824] Trial 40 finished with value: 0.9533432529170024 and parameters: {'num_leaves': 13, 'learning_rate': 0.2096972654686191, 'n_estimators': 52, 'lambda_l1': 0.3279881549545897}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:19:59,996] Trial 41 finished with value: 0.9547151094475921 and parameters: {'num_leaves': 23, 'learning_rate': 0.13242280484104288, 'n_estimators': 57, 'lambda_l1': 0.4798776150400185}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:00,161] Trial 42 finished with value: 0.9542164003268896 and parameters: {'num_leaves': 21, 'learning_rate': 0.11463274431566457, 'n_estimators': 50, 'lambda_l1': 0.5213593818230753}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:00,334] Trial 43 finished with value: 0.9542463430588017 and parameters: {'num_leaves': 24, 'learning_rate': 0.13911876178481689, 'n_estimators': 56, 'lambda_l1': 0.38484781409534924}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:00,465] Trial 44 finished with value: 0.9537609661562119 and parameters: {'num_leaves': 19, 'learning_rate': 0.10940436895050888, 'n_estimators': 38, 'lambda_l1': 0.4740930700078447}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:00,618] Trial 45 finished with value: 0.9535534050537035 and parameters: {'num_leaves': 23, 'learning_rate': 0.10352297218900477, 'n_estimators': 45, 'lambda_l1': 0.7502000055288868}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:00,740] Trial 46 finished with value: 0.9477711578183609 and parameters: {'num_leaves': 22, 'learning_rate': 0.5816476812414411, 'n_estimators': 24, 'lambda_l1': 0.3318450478619806}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:00,884] Trial 47 finished with value: 0.9534914837961757 and parameters: {'num_leaves': 15, 'learning_rate': 0.1540912623021495, 'n_estimators': 61, 'lambda_l1': 0.5613287058030524}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:01,018] Trial 48 finished with value: 0.953887580685132 and parameters: {'num_leaves': 9, 'learning_rate': 0.18534744733731467, 'n_estimators': 66, 'lambda_l1': 0.45064968486020235}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:01,182] Trial 49 finished with value: 0.9541694913413359 and parameters: {'num_leaves': 23, 'learning_rate': 0.1252142538746212, 'n_estimators': 54, 'lambda_l1': 0.2084149302769444}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:01,284] Trial 50 finished with value: 0.894213208204966 and parameters: {'num_leaves': 28, 'learning_rate': 0.1367250279591915, 'n_estimators': 10, 'lambda_l1': 0.379269383233047}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:01,502] Trial 51 finished with value: 0.9540840601134498 and parameters: {'num_leaves': 26, 'learning_rate': 0.13167720439912636, 'n_estimators': 79, 'lambda_l1': 0.23702159360282007}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:01,709] Trial 52 finished with value: 0.9542533996652893 and parameters: {'num_leaves': 26, 'learning_rate': 0.1134174849144728, 'n_estimators': 72, 'lambda_l1': 0.6350283036940974}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:01,894] Trial 53 finished with value: 0.9545320020193723 and parameters: {'num_leaves': 24, 'learning_rate': 0.14993006814293872, 'n_estimators': 60, 'lambda_l1': 0.11534128010064393}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:02,113] Trial 54 finished with value: 0.9548228607978487 and parameters: {'num_leaves': 21, 'learning_rate': 0.13605402095518418, 'n_estimators': 97, 'lambda_l1': 0.26791763674371183}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:02,342] Trial 55 finished with value: 0.9544885083544269 and parameters: {'num_leaves': 21, 'learning_rate': 0.1023100821825111, 'n_estimators': 99, 'lambda_l1': 0.2642041038115153}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:02,537] Trial 56 finished with value: 0.9537688243344843 and parameters: {'num_leaves': 18, 'learning_rate': 0.16636322144247406, 'n_estimators': 89, 'lambda_l1': 0.20777727167746954}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:02,756] Trial 57 finished with value: 0.9549173699899874 and parameters: {'num_leaves': 21, 'learning_rate': 0.11966556588802736, 'n_estimators': 96, 'lambda_l1': 0.3007747575282122}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:02,943] Trial 58 finished with value: 0.9543390190459443 and parameters: {'num_leaves': 16, 'learning_rate': 0.14296749635690467, 'n_estimators': 97, 'lambda_l1': 0.3509929113472401}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:03,138] Trial 59 finished with value: 0.953265993298085 and parameters: {'num_leaves': 19, 'learning_rate': 0.1749816044974637, 'n_estimators': 95, 'lambda_l1': 0.2993837378676236}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:03,357] Trial 60 finished with value: 0.9513990521612873 and parameters: {'num_leaves': 21, 'learning_rate': 0.25012134035921657, 'n_estimators': 95, 'lambda_l1': 0.2631208859225127}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:03,554] Trial 61 finished with value: 0.9546323810093938 and parameters: {'num_leaves': 19, 'learning_rate': 0.12062027277335785, 'n_estimators': 89, 'lambda_l1': 0.4160313208301153}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:03,794] Trial 62 finished with value: 0.9539299928611437 and parameters: {'num_leaves': 23, 'learning_rate': 0.1339654144393962, 'n_estimators': 100, 'lambda_l1': 0.3155658182125469}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:04,002] Trial 63 finished with value: 0.9548162332064155 and parameters: {'num_leaves': 22, 'learning_rate': 0.1002627563813601, 'n_estimators': 84, 'lambda_l1': 0.2151034600191249}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:04,220] Trial 64 finished with value: 0.9546048565545577 and parameters: {'num_leaves': 21, 'learning_rate': 0.1003140172581998, 'n_estimators': 91, 'lambda_l1': 0.2438234393129791}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:04,420] Trial 65 finished with value: 0.9548634812495846 and parameters: {'num_leaves': 22, 'learning_rate': 0.11069807843850041, 'n_estimators': 82, 'lambda_l1': 0.21202042118454736}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:04,619] Trial 66 finished with value: 0.9548456784915024 and parameters: {'num_leaves': 22, 'learning_rate': 0.1092489424930035, 'n_estimators': 84, 'lambda_l1': 0.2137998292594891}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:04,821] Trial 67 finished with value: 0.9549531597397994 and parameters: {'num_leaves': 22, 'learning_rate': 0.10841640043895576, 'n_estimators': 75, 'lambda_l1': 0.22309245113503717}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:05,030] Trial 68 finished with value: 0.9545861720720152 and parameters: {'num_leaves': 24, 'learning_rate': 0.11124577480250579, 'n_estimators': 76, 'lambda_l1': 0.27910844217607733}. Best is trial 13 with value: 0.9552355298321409.\n",
      "[I 2025-01-13 23:20:05,216] Trial 69 finished with value: 0.9552771751521227 and parameters: {'num_leaves': 17, 'learning_rate': 0.11562996573396564, 'n_estimators': 82, 'lambda_l1': 0.22607386545691477}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:05,374] Trial 70 finished with value: 0.9541268836941196 and parameters: {'num_leaves': 13, 'learning_rate': 0.11950131695523017, 'n_estimators': 82, 'lambda_l1': 0.1943804549689187}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:05,549] Trial 71 finished with value: 0.9546931779000699 and parameters: {'num_leaves': 15, 'learning_rate': 0.1083641329337981, 'n_estimators': 88, 'lambda_l1': 0.17467109058740504}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:05,758] Trial 72 finished with value: 0.9545475074880773 and parameters: {'num_leaves': 18, 'learning_rate': 0.11673570883944276, 'n_estimators': 93, 'lambda_l1': 0.22637845819137914}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:05,934] Trial 73 finished with value: 0.9544072938579177 and parameters: {'num_leaves': 17, 'learning_rate': 0.10712945544873666, 'n_estimators': 77, 'lambda_l1': 0.2268216284517331}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:06,217] Trial 74 finished with value: 0.9550118644965754 and parameters: {'num_leaves': 22, 'learning_rate': 0.1267036887830088, 'n_estimators': 84, 'lambda_l1': 0.2532531008907279}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:06,440] Trial 75 finished with value: 0.9548191674473138 and parameters: {'num_leaves': 25, 'learning_rate': 0.12000905714104508, 'n_estimators': 74, 'lambda_l1': 0.24677590955846218}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:06,649] Trial 76 finished with value: 0.9545606018830229 and parameters: {'num_leaves': 20, 'learning_rate': 0.12627524165407938, 'n_estimators': 84, 'lambda_l1': 0.19220535535240393}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:06,857] Trial 77 finished with value: 0.954184931766207 and parameters: {'num_leaves': 22, 'learning_rate': 0.14475299254132654, 'n_estimators': 80, 'lambda_l1': 0.1507943293471687}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:07,026] Trial 78 finished with value: 0.9328450384741324 and parameters: {'num_leaves': 19, 'learning_rate': 0.865549763057895, 'n_estimators': 69, 'lambda_l1': 0.21707571810710136}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:07,149] Trial 79 finished with value: 0.9479797265009241 and parameters: {'num_leaves': 4, 'learning_rate': 0.10868368763056196, 'n_estimators': 86, 'lambda_l1': 0.30142225119099536}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:07,365] Trial 80 finished with value: 0.9543304258591571 and parameters: {'num_leaves': 22, 'learning_rate': 0.11494908892393918, 'n_estimators': 92, 'lambda_l1': 0.18403542088640765}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:07,594] Trial 81 finished with value: 0.9545707792612301 and parameters: {'num_leaves': 21, 'learning_rate': 0.12810858773527622, 'n_estimators': 97, 'lambda_l1': 0.2592994689327842}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:07,803] Trial 82 finished with value: 0.9537807671163455 and parameters: {'num_leaves': 24, 'learning_rate': 0.13975074702746682, 'n_estimators': 83, 'lambda_l1': 0.26727778448447836}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:08,044] Trial 83 finished with value: 0.9547485615897747 and parameters: {'num_leaves': 23, 'learning_rate': 0.10598602273550357, 'n_estimators': 95, 'lambda_l1': 0.276826105047458}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:08,210] Trial 84 finished with value: 0.9545201225627243 and parameters: {'num_leaves': 14, 'learning_rate': 0.11736496891367272, 'n_estimators': 87, 'lambda_l1': 0.23469573428956345}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:08,420] Trial 85 finished with value: 0.9543862889749652 and parameters: {'num_leaves': 25, 'learning_rate': 0.15450407969191857, 'n_estimators': 78, 'lambda_l1': 0.20495231456940027}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:08,610] Trial 86 finished with value: 0.9547057186187852 and parameters: {'num_leaves': 20, 'learning_rate': 0.12829162127673466, 'n_estimators': 73, 'lambda_l1': 0.24811253488869128}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:08,861] Trial 87 finished with value: 0.9537181087923697 and parameters: {'num_leaves': 30, 'learning_rate': 0.1356591455586396, 'n_estimators': 91, 'lambda_l1': 0.216181871105273}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:09,061] Trial 88 finished with value: 0.9548614310996845 and parameters: {'num_leaves': 21, 'learning_rate': 0.11194988221153332, 'n_estimators': 81, 'lambda_l1': 0.2876882865230423}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:09,239] Trial 89 finished with value: 0.9550795843633243 and parameters: {'num_leaves': 17, 'learning_rate': 0.10839595596594277, 'n_estimators': 81, 'lambda_l1': 0.318633637971186}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:09,408] Trial 90 finished with value: 0.9547162474817329 and parameters: {'num_leaves': 18, 'learning_rate': 0.11043016423507858, 'n_estimators': 66, 'lambda_l1': 0.3583646464374247}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:09,565] Trial 91 finished with value: 0.9541055765435041 and parameters: {'num_leaves': 11, 'learning_rate': 0.12218539123826513, 'n_estimators': 80, 'lambda_l1': 0.32133508034233443}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:09,744] Trial 92 finished with value: 0.9542270601410642 and parameters: {'num_leaves': 17, 'learning_rate': 0.1056823153556055, 'n_estimators': 75, 'lambda_l1': 0.29532158504923667}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:09,973] Trial 93 finished with value: 0.954512614241366 and parameters: {'num_leaves': 27, 'learning_rate': 0.11295414464861489, 'n_estimators': 82, 'lambda_l1': 0.343529108457941}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:10,185] Trial 94 finished with value: 0.9549113099732219 and parameters: {'num_leaves': 22, 'learning_rate': 0.11982402917101892, 'n_estimators': 86, 'lambda_l1': 0.2303271871401638}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:10,396] Trial 95 finished with value: 0.9548569325883841 and parameters: {'num_leaves': 23, 'learning_rate': 0.10077772857669595, 'n_estimators': 89, 'lambda_l1': 0.18051601083559218}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:10,616] Trial 96 finished with value: 0.954705156399911 and parameters: {'num_leaves': 23, 'learning_rate': 0.10139814221069167, 'n_estimators': 89, 'lambda_l1': 0.16792257475610042}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:10,815] Trial 97 finished with value: 0.9479804315141097 and parameters: {'num_leaves': 19, 'learning_rate': 0.460664100048008, 'n_estimators': 87, 'lambda_l1': 0.2006880737958066}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:10,993] Trial 98 finished with value: 0.9417750073491097 and parameters: {'num_leaves': 16, 'learning_rate': 0.6781497078442521, 'n_estimators': 78, 'lambda_l1': 0.2260465657368048}. Best is trial 69 with value: 0.9552771751521227.\n",
      "[I 2025-01-13 23:20:11,206] Trial 99 finished with value: 0.9548756358791929 and parameters: {'num_leaves': 20, 'learning_rate': 0.11992514148680994, 'n_estimators': 94, 'lambda_l1': 0.18555664155030016}. Best is trial 69 with value: 0.9552771751521227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'num_leaves': 17, 'learning_rate': 0.11562996573396564, 'n_estimators': 82, 'lambda_l1': 0.22607386545691477}\n",
      "Best performance:  0.9552771751521227\n"
     ]
    }
   ],
   "source": [
    "X_trial = X_train_scaled\n",
    "y_trial = y_train\n",
    "\n",
    "# Define the objective function and suggest hyperparameters values\n",
    "def objective(trial):\n",
    "\n",
    "    svc_num_leaves = trial.suggest_int('num_leaves', 2, 31)\n",
    "    svc_learning_rate = trial.suggest_loguniform('learning_rate', 0.1, 1)\n",
    "    svc_n_estimators = trial.suggest_int('n_estimators', 1, 100)\n",
    "    svc_lambda_l1 = trial.suggest_loguniform('lambda_l1', 0.1, 1) \n",
    "    clf = lightgbm.LGBMRegressor (num_leaves = svc_num_leaves, learning_rate =svc_learning_rate, n_estimators = svc_n_estimators, lambda_l1 = svc_lambda_l1)\n",
    "    return cross_val_score(clf, X_trial, y_trial, n_jobs=-1, cv=3).mean()\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best set of hyperparameters\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "# Print the corresponding performance\n",
    "print('Best performance: ', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.22607386545691477, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22607386545691477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22607386545691477, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22607386545691477\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1063\n",
      "[LightGBM] [Info] Number of data points in the train set: 10763, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 1.210629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fitzm\\anaconda3\\envs\\fantasy\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model = lightgbm.LGBMRegressor(num_leaves = best_params['num_leaves'], learning_rate=best_params['learning_rate'], n_estimators = best_params['n_estimators'], lambda_l1 = best_params['lambda_l1'])\n",
    "\n",
    "model = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUTURE DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data_2 = future_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fitzm\\AppData\\Local\\Temp\\ipykernel_24936\\3751143350.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future_data_2[col] = pd.to_numeric(future_data_2[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Convert all object columns to float\n",
    "for col in future_data_2.select_dtypes(include=['object']).columns:\n",
    "    future_data_2[col] = pd.to_numeric(future_data_2[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fitzm\\AppData\\Local\\Temp\\ipykernel_24936\\1223409416.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future_data_2['event'] = future_data_2['event'].fillna(0)\n",
      "C:\\Users\\fitzm\\AppData\\Local\\Temp\\ipykernel_24936\\1223409416.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future_data_2['event'] = future_data_2['event'].astype('int64')\n"
     ]
    }
   ],
   "source": [
    "future_data_2['event'] = future_data_2['event'].fillna(0)\n",
    "future_data_2['event'] = future_data_2['event'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fitzm\\AppData\\Local\\Temp\\ipykernel_24936\\2831743559.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future_data_2['is_home'] = future_data_2['is_home'].astype('bool')\n",
      "C:\\Users\\fitzm\\AppData\\Local\\Temp\\ipykernel_24936\\2831743559.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  future_data_2['id_player'] = future_data_2['id_player'].astype('int64')\n"
     ]
    }
   ],
   "source": [
    "future_data_2['is_home'] = future_data_2['is_home'].astype('bool')\n",
    "\n",
    "future_data_2['id_player'] = future_data_2['id_player'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_predict_on = future_data_2.drop(columns = ['total_points','event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "data_to_predict_on_scaled = scaler.fit_transform(data_to_predict_on)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.22607386545691477, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22607386545691477\n"
     ]
    }
   ],
   "source": [
    "y_future = model.predict(data_to_predict_on_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_points = pd.DataFrame(y_future, columns=(['predicted_points']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = future_data_2.merge(future_points, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'chips': [...],\n",
      "  'element_stats': [...],\n",
      "  'element_types': [...],\n",
      "  'elements': [...],\n",
      "  'events': [...],\n",
      "  'game_config': {...},\n",
      "  'game_settings': {...},\n",
      "  'phases': [...],\n",
      "  'teams': [...],\n",
      "  'total_players': 11154704}\n"
     ]
    }
   ],
   "source": [
    "# base url for all FPL API endpoints\n",
    "base_url = 'https://fantasy.premierleague.com/api/'\n",
    "\n",
    "# get data from bootstrap-static endpoint\n",
    "r = requests.get(base_url+'bootstrap-static/').json()\n",
    "\n",
    "# show the top level fields\n",
    "pprint(r, indent=2, depth=1, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# create players dataframe\n",
    "players = pd.json_normalize(r['elements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = predicted_data.merge(players[['id', 'first_name', 'second_name']], left_on= 'id_player', right_on = 'id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = predicted_data[['id_player', 'first_name', 'second_name', 'opponent_team', 'is_home', 'cumulative_points','bps', 'total_points', 'event', 'predicted_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fitzm\\anaconda3\\envs\\fantasy\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LGBMRegressor' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[198], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get feature coefficients\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get feature names (if available, e.g., if X_train is a DataFrame)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LGBMRegressor' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "# Get feature coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Get feature names (if available, e.g., if X_train is a DataFrame)\n",
    "try:\n",
    "    feature_names = X_train.columns\n",
    "except AttributeError:\n",
    "    feature_names = [f\"Feature {i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "# Combine feature names with coefficients\n",
    "feature_importance = list(zip(feature_names, coefficients))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantasy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
